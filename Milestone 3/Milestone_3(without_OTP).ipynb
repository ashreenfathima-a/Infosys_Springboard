{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "cWPVM3WzI1de"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install streamlit pyngrok bcrypt pyjwt pandas transformers torch accelerate bitsandbytes sentencepiece -q\n",
        "\n",
        "# Import necessary libraries\n",
        "import streamlit as st\n",
        "import sqlite3\n",
        "import bcrypt\n",
        "import jwt\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(\"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\")"
      ],
      "metadata": {
        "id": "Y-kbohrKYgBE"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Authentication Backend\n",
        "SECRET_KEY = \"your-super-secret-jwt-key\"\n",
        "\n",
        "def init_db():\n",
        "    \"\"\"Initialize SQLite database with users table\"\"\"\n",
        "    conn = sqlite3.connect('integrated_app.db')\n",
        "    c = conn.cursor()\n",
        "    c.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS users (\n",
        "            email TEXT PRIMARY KEY,\n",
        "            password_hash BLOB NOT NULL,\n",
        "            role TEXT NOT NULL,\n",
        "            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        "        )\n",
        "    ''')\n",
        "\n",
        "    # Add default admin user\n",
        "    c.execute(\"SELECT * FROM users WHERE email='admin@ai'\")\n",
        "    if c.fetchone() is None:\n",
        "        admin_email = \"admin@ai\"\n",
        "        admin_pass = \"Admin123!\"\n",
        "        hashed_pass = bcrypt.hashpw(admin_pass.encode(), bcrypt.gensalt())\n",
        "        c.execute(\"INSERT INTO users (email, password_hash, role) VALUES (?, ?, ?)\",\n",
        "                  (admin_email, hashed_pass, \"Admin\"))\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def authenticate_user(email, password):\n",
        "    \"\"\"Authenticate user and return JWT token\"\"\"\n",
        "    conn = sqlite3.connect('integrated_app.db')\n",
        "    c = conn.cursor()\n",
        "    c.execute(\"SELECT password_hash, role FROM users WHERE email=?\", (email,))\n",
        "    result = c.fetchone()\n",
        "    conn.close()\n",
        "\n",
        "    if result and bcrypt.checkpw(password.encode(), result[0]):\n",
        "        payload = {\n",
        "            'exp': datetime.utcnow() + timedelta(hours=2),\n",
        "            'iat': datetime.utcnow(),\n",
        "            'sub': email,\n",
        "            'role': result[1]\n",
        "        }\n",
        "        return jwt.encode(payload, SECRET_KEY, algorithm='HS256')\n",
        "    return None\n",
        "\n",
        "def register_user(email, password, role=\"General User\"):\n",
        "    \"\"\"Register new user\"\"\"\n",
        "    conn = sqlite3.connect('integrated_app.db')\n",
        "    c = conn.cursor()\n",
        "\n",
        "    c.execute(\"SELECT * FROM users WHERE email=?\", (email,))\n",
        "    if c.fetchone():\n",
        "        conn.close()\n",
        "        return \"Email already exists!\"\n",
        "\n",
        "    hashed_password = bcrypt.hashpw(password.encode('utf-8'), bcrypt.gensalt())\n",
        "    c.execute(\"INSERT INTO users (email, password_hash, role) VALUES (?, ?, ?)\",\n",
        "              (email, hashed_password, role))\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    return \"User registered successfully!\""
      ],
      "metadata": {
        "id": "IxDIYDm1Javy"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AI Model Configuration\n",
        "@st.cache_resource\n",
        "def setup_ai_models():\n",
        "    \"\"\"Setup and cache AI models\"\"\"\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "    # Check GPU availability\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Quantization config for efficient loading\n",
        "    quantization_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "        bnb_4bit_quant_type=\"nf4\"\n",
        "    )\n",
        "\n",
        "    # Load CodeBERT for code understanding\n",
        "    print(\"Loading CodeBERT...\")\n",
        "    codebert_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "    codebert_model = AutoModel.from_pretrained(\"microsoft/codebert-base\").to(device)\n",
        "\n",
        "    # Load Gemma for Python explanation\n",
        "    print(\"Loading Gemma...\")\n",
        "    gemma_model_id = \"google/gemma-2b-it\"\n",
        "    gemma_tokenizer = AutoTokenizer.from_pretrained(gemma_model_id)\n",
        "\n",
        "    gemma_chat_template = (\n",
        "        \"{% for message in messages %}\"\n",
        "        \"{% if message['role'] == 'user' %}\"\n",
        "        \"<start_of_turn>user\\n{{ message['content'] }}<end_of_turn>\\n\"\n",
        "        \"{% elif message['role'] == 'model' %}\"\n",
        "        \"<start_of_turn>model\\n{{ message['content'] }}<end_of_turn>\\n\"\n",
        "        \"{% endif %}\"\n",
        "        \"{% endfor %}\"\n",
        "        \"{% if add_generation_prompt %}\"\n",
        "        \"<start_of_turn>model\\n\"\n",
        "        \"{% endif %}\"\n",
        "    )\n",
        "    gemma_tokenizer.chat_template = gemma_chat_template\n",
        "\n",
        "    gemma_model = AutoModelForCausalLM.from_pretrained(\n",
        "        gemma_model_id,\n",
        "        quantization_config=quantization_config,\n",
        "        device_map=\"auto\",\n",
        "    )\n",
        "\n",
        "    # Load DeepSeek for code generation\n",
        "    print(\"Loading DeepSeek...\")\n",
        "    deepseek_model_id = \"deepseek-ai/deepseek-coder-1.3b-instruct\"\n",
        "    deepseek_tokenizer = AutoTokenizer.from_pretrained(deepseek_model_id, trust_remote_code=True)\n",
        "    deepseek_model = AutoModelForCausalLM.from_pretrained(\n",
        "        deepseek_model_id,\n",
        "        quantization_config=quantization_config,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        'device': device,\n",
        "        'codebert_tokenizer': codebert_tokenizer,\n",
        "        'codebert_model': codebert_model,\n",
        "        'gemma_tokenizer': gemma_tokenizer,\n",
        "        'gemma_model': gemma_model,\n",
        "        'deepseek_tokenizer': deepseek_tokenizer,\n",
        "        'deepseek_model': deepseek_model\n",
        "    }\n",
        "\n",
        "def explain_code(code, language, models):\n",
        "    \"\"\"Explain code using appropriate AI model\"\"\"\n",
        "    device = models['device']\n",
        "\n",
        "    if language == \"python\":\n",
        "        # Use Gemma for Python\n",
        "        messages = [\n",
        "            {\"role\": \"user\", \"content\": f\"Explain this Python code in simple terms:\\n\\n```python\\n{code}\\n```\"}\n",
        "        ]\n",
        "        prompt = models['gemma_tokenizer'].apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "        inputs = models['gemma_tokenizer'](prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = models['gemma_model'].generate(\n",
        "                **inputs, max_new_tokens=250, do_sample=True, temperature=0.7\n",
        "            )\n",
        "\n",
        "        input_len = inputs[\"input_ids\"].shape[1]\n",
        "        return models['gemma_tokenizer'].decode(outputs[0][input_len:], skip_special_tokens=True)\n",
        "\n",
        "    else:\n",
        "        # Use DeepSeek for other languages\n",
        "        messages = [\n",
        "            {\"role\": \"user\", \"content\": f\"Explain this {language} code simply:\\n\\n```{language}\\n{code}\\n```\"}\n",
        "        ]\n",
        "        prompt = models['deepseek_tokenizer'].apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "        inputs = models['deepseek_tokenizer'](prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = models['deepseek_model'].generate(\n",
        "                **inputs, max_new_tokens=250, do_sample=True, temperature=0.7\n",
        "            )\n",
        "\n",
        "        input_len = inputs[\"input_ids\"].shape[1]\n",
        "        return models['deepseek_tokenizer'].decode(outputs[0][input_len:], skip_special_tokens=True)\n",
        "\n",
        "def generate_code(prompt, models):\n",
        "    \"\"\"Generate code using DeepSeek\"\"\"\n",
        "    device = models['device']\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": f\"You are an expert coding assistant. {prompt}\"}\n",
        "    ]\n",
        "    prompt = models['deepseek_tokenizer'].apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    inputs = models['deepseek_tokenizer'](prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = models['deepseek_model'].generate(\n",
        "            **inputs, max_new_tokens=300, do_sample=True, temperature=0.2\n",
        "        )\n",
        "\n",
        "    input_len = inputs[\"input_ids\"].shape[1]\n",
        "    return models['deepseek_tokenizer'].decode(outputs[0][input_len:], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "cVpGWy1nJytE"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Streamlit App\n",
        "def main():\n",
        "    st.set_page_config(page_title=\"AI Code Assistant\", layout=\"wide\")\n",
        "\n",
        "    # Initialize database\n",
        "    init_db()\n",
        "\n",
        "    # Custom CSS\n",
        "    st.markdown(\"\"\"\n",
        "    <style>\n",
        "    .main { padding: 0rem; }\n",
        "    .stTabs [data-baseweb=\"tab-list\"] { gap: 20px; }\n",
        "    .stTabs [data-baseweb=\"tab\"] {\n",
        "        height: 50px;\n",
        "        padding-left: 20px;\n",
        "        padding-right: 20px;\n",
        "    }\n",
        "    </style>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    # Session state initialization\n",
        "    if 'token' not in st.session_state:\n",
        "        st.session_state.token = None\n",
        "    if 'models' not in st.session_state:\n",
        "        st.session_state.models = None\n",
        "\n",
        "    # Decode token\n",
        "    try:\n",
        "        if st.session_state.token:\n",
        "            payload = jwt.decode(st.session_state.token, SECRET_KEY, algorithms=['HS256'])\n",
        "        else:\n",
        "            payload = None\n",
        "    except:\n",
        "        payload = None\n",
        "        st.session_state.token = None\n",
        "\n",
        "    # Main app logic\n",
        "    if payload is None:\n",
        "        show_login_page()\n",
        "    else:\n",
        "        show_main_app(payload)\n",
        "\n",
        "def show_login_page():\n",
        "    \"\"\"Display login/registration page\"\"\"\n",
        "    st.title(\"🔐 AI Code Assistant - Login\")\n",
        "\n",
        "    col1, col2, col3 = st.columns([1, 2, 1])\n",
        "    with col2:\n",
        "        tab1, tab2 = st.tabs([\"Login\", \"Register\"])\n",
        "\n",
        "        with tab1:\n",
        "            with st.form(\"login_form\"):\n",
        "                email = st.text_input(\"Email\", placeholder=\"your@email.com\")\n",
        "                password = st.text_input(\"Password\", type=\"password\")\n",
        "                submit = st.form_submit_button(\"Login\", type=\"primary\")\n",
        "\n",
        "                if submit:\n",
        "                    token = authenticate_user(email, password)\n",
        "                    if token:\n",
        "                        st.session_state.token = token\n",
        "                        st.success(\"✅ Login successful!\")\n",
        "                        st.rerun()\n",
        "                    else:\n",
        "                        st.error(\"Invalid credentials!\")\n",
        "\n",
        "        with tab2:\n",
        "            with st.form(\"register_form\"):\n",
        "                new_email = st.text_input(\"Email\", key=\"reg_email\")\n",
        "                new_password = st.text_input(\"Password\", type=\"password\", key=\"reg_pass\")\n",
        "                confirm_password = st.text_input(\"Confirm Password\", type=\"password\", key=\"reg_confirm\")\n",
        "                role = st.selectbox(\"Role\", [\"General User\", \"Developer\", \"Student\"])\n",
        "\n",
        "                if st.form_submit_button(\"Register\"):\n",
        "                    if new_password == confirm_password:\n",
        "                        result = register_user(new_email, new_password, role)\n",
        "                        if \"successfully\" in result:\n",
        "                            st.success(result)\n",
        "                        else:\n",
        "                            st.error(result)\n",
        "                    else:\n",
        "                        st.error(\"Passwords don't match!\")\n",
        "\n",
        "def show_main_app(payload):\n",
        "    \"\"\"Display main application after login\"\"\"\n",
        "    # Sidebar\n",
        "    with st.sidebar:\n",
        "        st.success(f\"👤 Welcome, {payload['sub']}!\")\n",
        "        st.info(f\"Role: {payload['role']}\")\n",
        "        if st.button(\"Logout\"):\n",
        "            st.session_state.token = None\n",
        "            st.rerun()\n",
        "\n",
        "    # Main content\n",
        "    st.title(\"🤖 AI Code Assistant\")\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # Load models if not already loaded\n",
        "    if st.session_state.models is None:\n",
        "        with st.spinner(\"Loading AI models... This may take a moment.\"):\n",
        "            st.session_state.models = setup_ai_models()\n",
        "        st.success(\"✅ Models loaded successfully!\")\n",
        "\n",
        "    # App functionality\n",
        "    col1, col2 = st.columns([1, 1])\n",
        "\n",
        "    with col1:\n",
        "        st.header(\"📝 Code Explanation\")\n",
        "        with st.form(\"explain_form\"):\n",
        "            code_input = st.text_area(\"Paste your code here:\", height=200,\n",
        "                                    placeholder=\"def hello_world():\\n    print('Hello, World!')\")\n",
        "            language = st.selectbox(\"Select language:\",\n",
        "                                  [\"python\", \"javascript\", \"sql\", \"java\", \"cpp\"])\n",
        "\n",
        "            if st.form_submit_button(\"Explain Code\", type=\"primary\"):\n",
        "                if code_input.strip():\n",
        "                    with st.spinner(\"Analyzing code...\"):\n",
        "                        explanation = explain_code(code_input, language, st.session_state.models)\n",
        "                        st.markdown(\"### 🎯 Explanation:\")\n",
        "                        st.markdown(explanation)\n",
        "                else:\n",
        "                    st.warning(\"Please enter some code to explain!\")\n",
        "\n",
        "    with col2:\n",
        "        st.header(\"⚡ Code Generation\")\n",
        "        with st.form(\"generate_form\"):\n",
        "            prompt = st.text_area(\"Describe what you want to generate:\", height=200,\n",
        "                                placeholder=\"Create a Python function to calculate factorial\")\n",
        "\n",
        "            if st.form_submit_button(\"Generate Code\", type=\"primary\"):\n",
        "                if prompt.strip():\n",
        "                    with st.spinner(\"Generating code...\"):\n",
        "                        generated_code = generate_code(prompt, st.session_state.models)\n",
        "                        st.markdown(\"### 🎯 Generated Code:\")\n",
        "                        st.code(generated_code, language=\"python\")\n",
        "                else:\n",
        "                    st.warning(\"Please enter a description!\")\n",
        "\n",
        "    # Additional features for logged-in users\n",
        "    if st.button(\"Show Sample Usage\"):\n",
        "        st.markdown(\"\"\"\n",
        "        ### 📚 Sample Usage\n",
        "\n",
        "        **Code Explanation Example:**\n",
        "        - Input: `def add(a, b): return a + b`\n",
        "        - Language: Python\n",
        "        - Output: This function takes two parameters and returns their sum...\n",
        "\n",
        "        **Code Generation Example:**\n",
        "        - Input: \"Create a function to reverse a string\"\n",
        "        - Output: A complete Python function with proper implementation\n",
        "        \"\"\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSfiKp0TJ5t4",
        "outputId": "6f012a62-a0f6-45d3-dc6e-37aa68e8e5af"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-10-27 11:17:21.007 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.011 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.011 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.012 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.014 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.014 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.015 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.016 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.017 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.018 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.022 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.022 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.023 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.024 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.025 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.037 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.042 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.048 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.050 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.050 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.052 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.055 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.057 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.060 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.061 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.065 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.066 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.067 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.068 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.070 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.071 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.073 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.074 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.076 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.077 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.080 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.081 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.082 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.084 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.085 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.086 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.087 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.088 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.089 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.091 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.092 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.092 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.092 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.093 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.095 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.096 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.096 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.098 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.098 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.099 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.100 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.100 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.101 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.103 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.103 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.105 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.106 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.106 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.107 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.107 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.108 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.110 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.111 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.112 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.112 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.113 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.113 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.115 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.116 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:21.118 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34fcd5bc"
      },
      "source": [
        "# Task\n",
        "Run all the cells in the notebook, fix any errors that occur during execution, and confirm that the Streamlit application is running successfully."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "190a49a9"
      },
      "source": [
        "## Execute all cells\n",
        "\n",
        "### Subtask:\n",
        "Run all the cells in the notebook in sequence.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc49c814"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask is to run all cells in the notebook. The first cell has already been executed successfully. The second cell has also been executed successfully. The third cell has also been executed successfully. The fourth cell has failed execution. The fifth cell has been executed successfully. The next step is to execute the fourth cell again to try and resolve the error.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b5b5c26",
        "outputId": "36a0824a-b3f3-48bf-d555-f41306cd5705"
      },
      "source": [
        "# Main Streamlit App\n",
        "def main():\n",
        "    st.set_page_config(page_title=\"AI Code Assistant\", layout=\"wide\")\n",
        "\n",
        "    # Initialize database\n",
        "    init_db()\n",
        "\n",
        "    # Custom CSS\n",
        "    st.markdown(\"\"\"\n",
        "    <style>\n",
        "    .main { padding: 0rem; }\n",
        "    .stTabs [data-baseweb=\"tab-list\"] { gap: 20px; }\n",
        "    .stTabs [data-baseweb=\"tab\"] {\n",
        "        height: 50px;\n",
        "        padding-left: 20px;\n",
        "        padding-right: 20px;\n",
        "    }\n",
        "    </style>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    # Session state initialization\n",
        "    if 'token' not in st.session_state:\n",
        "        st.session_state.token = None\n",
        "    if 'models' not in st.session_state:\n",
        "        st.session_state.models = None\n",
        "\n",
        "    # Decode token\n",
        "    try:\n",
        "        if st.session_state.token:\n",
        "            payload = jwt.decode(st.session_state.token, SECRET_KEY, algorithms=['HS256'])\n",
        "        else:\n",
        "            payload = None\n",
        "    except:\n",
        "        payload = None\n",
        "        st.session_state.token = None\n",
        "\n",
        "    # Main app logic\n",
        "    if payload is None:\n",
        "        show_login_page()\n",
        "    else:\n",
        "        show_main_app(payload)\n",
        "\n",
        "def show_login_page():\n",
        "    \"\"\"Display login/registration page\"\"\"\n",
        "    st.title(\"🔐 AI Code Assistant - Login\")\n",
        "\n",
        "    col1, col2, col3 = st.columns([1, 2, 1])\n",
        "    with col2:\n",
        "        tab1, tab2 = st.tabs([\"Login\", \"Register\"])\n",
        "\n",
        "        with tab1:\n",
        "            with st.form(\"login_form\"):\n",
        "                email = st.text_input(\"Email\", placeholder=\"your@email.com\")\n",
        "                password = st.text_input(\"Password\", type=\"password\")\n",
        "                submit = st.form_submit_button(\"Login\", type=\"primary\")\n",
        "\n",
        "                if submit:\n",
        "                    token = authenticate_user(email, password)\n",
        "                    if token:\n",
        "                        st.session_state.token = token\n",
        "                        st.success(\"✅ Login successful!\")\n",
        "                        st.rerun()\n",
        "                    else:\n",
        "                        st.error(\"Invalid credentials!\")\n",
        "\n",
        "        with tab2:\n",
        "            with st.form(\"register_form\"):\n",
        "                new_email = st.text_input(\"Email\", key=\"reg_email\")\n",
        "                new_password = st.text_input(\"Password\", type=\"password\", key=\"reg_pass\")\n",
        "                confirm_password = st.text_input(\"Confirm Password\", type=\"password\", key=\"reg_confirm\")\n",
        "                role = st.selectbox(\"Role\", [\"General User\", \"Developer\", \"Student\"])\n",
        "\n",
        "                if st.form_submit_button(\"Register\"):\n",
        "                    if new_password == confirm_password:\n",
        "                        result = register_user(new_email, new_password, role)\n",
        "                        if \"successfully\" in result:\n",
        "                            st.success(result)\n",
        "                        else:\n",
        "                            st.error(result)\n",
        "                    else:\n",
        "                        st.error(\"Passwords don't match!\")\n",
        "\n",
        "def show_main_app(payload):\n",
        "    \"\"\"Display main application after login\"\"\"\n",
        "    # Sidebar\n",
        "    with st.sidebar:\n",
        "        st.success(f\"👤 Welcome, {payload['sub']}!\")\n",
        "        st.info(f\"Role: {payload['role']}\")\n",
        "        if st.button(\"Logout\"):\n",
        "            st.session_state.token = None\n",
        "            st.rerun()\n",
        "\n",
        "    # Main content\n",
        "    st.title(\"🤖 AI Code Assistant\")\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # Load models if not already loaded\n",
        "    if st.session_state.models is None:\n",
        "        with st.spinner(\"Loading AI models... This may take a moment.\"):\n",
        "            st.session_state.models = setup_ai_models()\n",
        "        st.success(\"✅ Models loaded successfully!\")\n",
        "\n",
        "    # App functionality\n",
        "    col1, col2 = st.columns([1, 1])\n",
        "\n",
        "    with col1:\n",
        "        st.header(\"📝 Code Explanation\")\n",
        "        with st.form(\"explain_form\"):\n",
        "            code_input = st.text_area(\"Paste your code here:\", height=200,\n",
        "                                    placeholder=\"def hello_world():\\n    print('Hello, World!')\")\n",
        "            language = st.selectbox(\"Select language:\",\n",
        "                                  [\"python\", \"javascript\", \"sql\", \"java\", \"cpp\"])\n",
        "\n",
        "            if st.form_submit_button(\"Explain Code\", type=\"primary\"):\n",
        "                if code_input.strip():\n",
        "                    with st.spinner(\"Analyzing code...\"):\n",
        "                        explanation = explain_code(code_input, language, st.session_state.models)\n",
        "                        st.markdown(\"### 🎯 Explanation:\")\n",
        "                        st.markdown(explanation)\n",
        "                else:\n",
        "                    st.warning(\"Please enter some code to explain!\")\n",
        "\n",
        "    with col2:\n",
        "        st.header(\"⚡ Code Generation\")\n",
        "        with st.form(\"generate_form\"):\n",
        "            prompt = st.text_area(\"Describe what you want to generate:\", height=200,\n",
        "                                placeholder=\"Create a Python function to calculate factorial\")\n",
        "\n",
        "            if st.form_submit_button(\"Generate Code\", type=\"primary\"):\n",
        "                if prompt.strip():\n",
        "                    with st.spinner(\"Generating code...\"):\n",
        "                        generated_code = generate_code(prompt, st.session_state.models)\n",
        "                        st.markdown(\"### 🎯 Generated Code:\")\n",
        "                        st.code(generated_code, language=\"python\")\n",
        "                else:\n",
        "                    st.warning(\"Please enter a description!\")\n",
        "\n",
        "    # Additional features for logged-in users\n",
        "    if st.button(\"Show Sample Usage\"):\n",
        "        st.markdown(\"\"\"\n",
        "        ### 📚 Sample Usage\n",
        "\n",
        "        **Code Explanation Example:**\n",
        "        - Input: `def add(a, b): return a + b`\n",
        "        - Language: Python\n",
        "        - Output: This function takes two parameters and returns their sum...\n",
        "\n",
        "        **Code Generation Example:**\n",
        "        - Input: \"Create a function to reverse a string\"\n",
        "        - Output: A complete Python function with proper implementation\n",
        "        \"\"\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-10-27 11:17:27.285 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.287 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.289 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.290 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.292 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.294 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.304 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.305 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.306 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.307 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.309 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.310 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.312 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.313 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.315 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.317 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.319 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.320 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.323 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.324 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.326 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.327 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.329 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.331 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.332 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.334 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.335 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.337 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.338 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.340 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.341 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.342 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.343 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.344 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.345 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.346 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.348 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.351 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.352 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.353 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.354 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.355 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.356 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.357 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.360 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.360 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.363 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.364 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.365 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.365 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.366 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.368 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.368 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.371 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.372 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.373 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.374 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.375 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.377 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.377 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.379 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.381 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.382 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.384 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.385 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.386 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.388 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.389 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.390 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.392 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.392 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.394 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.394 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.400 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-27 11:17:27.400 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3635242b"
      },
      "source": [
        "**Reasoning**:\n",
        "The fourth cell failed again with a `SyntaxError: unterminated f-string literal`. This error indicates an issue with how f-strings are used within the multiline string for the `gemma_chat_template`. The traceback points to line 144 in the integrated_app.py file which corresponds to this part of the code. The issue is likely due to newline characters within the f-string which are not escaped properly when constructing the multiline string. I will try to fix the f-string by escaping the newline characters within the string literal.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================\n",
        "# ✅ INTEGRATED AI CODE ASSISTANT (COLAB + STREAMLIT)\n",
        "# ==============================================\n",
        "\n",
        "# Save the complete code to a file\n",
        "complete_code = '''\n",
        "import streamlit as st\n",
        "import sqlite3\n",
        "import bcrypt\n",
        "import jwt\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "import time\n",
        "from huggingface_hub import login\n",
        "login(\"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\")\n",
        "\n",
        "# ===============================\n",
        "# 🔐 AUTHENTICATION BACKEND\n",
        "# ===============================\n",
        "\n",
        "SECRET_KEY = \"your-super-secret-jwt-key\"\n",
        "\n",
        "def init_db():\n",
        "    \"\"\"Initialize SQLite database with users table\"\"\"\n",
        "    conn = sqlite3.connect('integrated_app.db')\n",
        "    c = conn.cursor()\n",
        "    c.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS users (\n",
        "            email TEXT PRIMARY KEY,\n",
        "            password_hash BLOB NOT NULL,\n",
        "            role TEXT NOT NULL,\n",
        "            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        "        )\n",
        "    \"\"\")\n",
        "\n",
        "    # Add default admin user\n",
        "    c.execute(\"SELECT * FROM users WHERE email='admin@ai'\")\n",
        "    if c.fetchone() is None:\n",
        "        admin_email = \"admin@ai\"\n",
        "        admin_pass = \"Admin123!\"\n",
        "        hashed_pass = bcrypt.hashpw(admin_pass.encode(), bcrypt.gensalt())\n",
        "        c.execute(\"INSERT INTO users (email, password_hash, role) VALUES (?, ?, ?)\",\n",
        "                  (admin_email, hashed_pass, \"Admin\"))\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def authenticate_user(email, password):\n",
        "    \"\"\"Authenticate user and return JWT token\"\"\"\n",
        "    conn = sqlite3.connect('integrated_app.db')\n",
        "    c = conn.cursor()\n",
        "    c.execute(\"SELECT password_hash, role FROM users WHERE email=?\", (email,))\n",
        "    result = c.fetchone()\n",
        "    conn.close()\n",
        "\n",
        "    if result and bcrypt.checkpw(password.encode(), result[0]):\n",
        "        payload = {\n",
        "            'exp': datetime.utcnow() + timedelta(hours=2),\n",
        "            'iat': datetime.utcnow(),\n",
        "            'sub': email,\n",
        "            'role': result[1]\n",
        "        }\n",
        "        return jwt.encode(payload, SECRET_KEY, algorithm='HS256')\n",
        "    return None\n",
        "\n",
        "def register_user(email, password, role=\"General User\"):\n",
        "    \"\"\"Register new user\"\"\"\n",
        "    conn = sqlite3.connect('integrated_app.db')\n",
        "    c = conn.cursor()\n",
        "\n",
        "    c.execute(\"SELECT * FROM users WHERE email=?\", (email,))\n",
        "    if c.fetchone():\n",
        "        conn.close()\n",
        "        return \"Email already exists!\"\n",
        "\n",
        "    hashed_password = bcrypt.hashpw(password.encode('utf-8'), bcrypt.gensalt())\n",
        "    c.execute(\"INSERT INTO users (email, password_hash, role) VALUES (?, ?, ?)\",\n",
        "              (email, hashed_password, role))\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    return \"User registered successfully!\"\n",
        "\n",
        "# ===============================\n",
        "# 🧠 AI MODEL CONFIGURATION\n",
        "# ===============================\n",
        "\n",
        "@st.cache_resource\n",
        "def setup_ai_models():\n",
        "    \"\"\"Setup and cache AI models\"\"\"\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    quantization_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "        bnb_4bit_quant_type=\"nf4\"\n",
        "    )\n",
        "\n",
        "    print(\"Loading CodeBERT...\")\n",
        "    codebert_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "    codebert_model = AutoModel.from_pretrained(\"microsoft/codebert-base\").to(device)\n",
        "\n",
        "    print(\"Loading Gemma...\")\n",
        "    gemma_model_id = \"google/gemma-2b-it\"\n",
        "    gemma_tokenizer = AutoTokenizer.from_pretrained(gemma_model_id)\n",
        "\n",
        "    gemma_chat_template = (\n",
        "        \"{% for message in messages %}\"\n",
        "        \"{% if message['role'] == 'user' %}\"\n",
        "        \"<start_of_turn>user\\\\n{{ message['content'] }}<end_of_turn>\\\\n\"\n",
        "        \"{% elif message['role'] == 'model' %}\"\n",
        "        \"<start_of_turn>model\\\\n{{ message['content'] }}<end_of_turn>\\\\n\"\n",
        "        \"{% endif %}\"\n",
        "        \"{% endfor %}\"\n",
        "        \"{% if add_generation_prompt %}\"\n",
        "        \"<start_of_turn>model\\\\n\"\n",
        "        \"{% endif %}\"\n",
        "    )\n",
        "    gemma_tokenizer.chat_template = gemma_chat_template\n",
        "\n",
        "    gemma_model = AutoModelForCausalLM.from_pretrained(\n",
        "        gemma_model_id,\n",
        "        quantization_config=quantization_config,\n",
        "        device_map=\"auto\",\n",
        "    )\n",
        "\n",
        "    print(\"Loading DeepSeek...\")\n",
        "    deepseek_model_id = \"deepseek-ai/deepseek-coder-1.3b-instruct\"\n",
        "    deepseek_tokenizer = AutoTokenizer.from_pretrained(deepseek_model_id, trust_remote_code=True)\n",
        "    deepseek_model = AutoModelForCausalLM.from_pretrained(\n",
        "        deepseek_model_id,\n",
        "        quantization_config=quantization_config,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        'device': device,\n",
        "        'codebert_tokenizer': codebert_tokenizer,\n",
        "        'codebert_model': codebert_model,\n",
        "        'gemma_tokenizer': gemma_tokenizer,\n",
        "        'gemma_model': gemma_model,\n",
        "        'deepseek_tokenizer': deepseek_tokenizer,\n",
        "        'deepseek_model': deepseek_model\n",
        "    }\n",
        "\n",
        "# ===============================\n",
        "# 💬 AI FUNCTIONALITY\n",
        "# ===============================\n",
        "\n",
        "def explain_code(code, language, models):\n",
        "    \"\"\"Explain code using AI model\"\"\"\n",
        "    device = models['device']\n",
        "\n",
        "    if language == \"python\":\n",
        "        messages = [\n",
        "            {\"role\": \"user\", \"content\": f\"Explain this Python code in simple terms:\\\\n\\\\n```python\\\\n{code}\\\\n```\"}\n",
        "        ]\n",
        "        prompt = models['gemma_tokenizer'].apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "        inputs = models['gemma_tokenizer'](prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = models['gemma_model'].generate(**inputs, max_new_tokens=250, do_sample=True, temperature=0.7)\n",
        "\n",
        "        input_len = inputs[\"input_ids\"].shape[1]\n",
        "        return models['gemma_tokenizer'].decode(outputs[0][input_len:], skip_special_tokens=True)\n",
        "\n",
        "    else:\n",
        "        messages = [\n",
        "            {\"role\": \"user\", \"content\": f\"Explain this {language} code:\\\\n\\\\n```{language}\\\\n{code}\\\\n```\"}\n",
        "        ]\n",
        "        prompt = models['deepseek_tokenizer'].apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "        inputs = models['deepseek_tokenizer'](prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = models['deepseek_model'].generate(**inputs, max_new_tokens=250, do_sample=True, temperature=0.7)\n",
        "\n",
        "        input_len = inputs[\"input_ids\"].shape[1]\n",
        "        return models['deepseek_tokenizer'].decode(outputs[0][input_len:], skip_special_tokens=True)\n",
        "\n",
        "def generate_code(prompt, models):\n",
        "    \"\"\"Generate code using DeepSeek\"\"\"\n",
        "    device = models['device']\n",
        "\n",
        "    messages = [{\"role\": \"user\", \"content\": f\"You are an expert coding assistant. {prompt}\"}]\n",
        "    prompt = models['deepseek_tokenizer'].apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    inputs = models['deepseek_tokenizer'](prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = models['deepseek_model'].generate(**inputs, max_new_tokens=300, do_sample=True, temperature=0.2)\n",
        "\n",
        "    input_len = inputs[\"input_ids\"].shape[1]\n",
        "    return models['deepseek_tokenizer'].decode(outputs[0][input_len:], skip_special_tokens=True)\n",
        "\n",
        "# ===============================\n",
        "# 🌐 STREAMLIT FRONTEND\n",
        "# ===============================\n",
        "\n",
        "def main():\n",
        "    st.set_page_config(page_title=\"AI Code Assistant\", layout=\"wide\")\n",
        "    init_db()\n",
        "\n",
        "    st.markdown(\"<style>.main {padding: 0rem;}</style>\", unsafe_allow_html=True)\n",
        "\n",
        "    if 'token' not in st.session_state:\n",
        "        st.session_state.token = None\n",
        "    if 'models' not in st.session_state:\n",
        "        st.session_state.models = None\n",
        "\n",
        "    try:\n",
        "        payload = jwt.decode(st.session_state.token, SECRET_KEY, algorithms=['HS256']) if st.session_state.token else None\n",
        "    except:\n",
        "        payload = None\n",
        "        st.session_state.token = None\n",
        "\n",
        "    if payload is None:\n",
        "        show_login_page()\n",
        "    else:\n",
        "        show_main_app(payload)\n",
        "\n",
        "def show_login_page():\n",
        "    st.title(\"🔐 AI Code Assistant - Login\")\n",
        "    col1, col2, col3 = st.columns([1,2,1])\n",
        "\n",
        "    with col2:\n",
        "        tab1, tab2 = st.tabs([\"Login\", \"Register\"])\n",
        "        with tab1:\n",
        "            with st.form(\"login_form\"):\n",
        "                email = st.text_input(\"Email\")\n",
        "                password = st.text_input(\"Password\", type=\"password\")\n",
        "                submit = st.form_submit_button(\"Login\")\n",
        "                if submit:\n",
        "                    token = authenticate_user(email, password)\n",
        "                    if token:\n",
        "                        st.session_state.token = token\n",
        "                        st.success(\"✅ Login successful!\")\n",
        "                        st.rerun()\n",
        "                    else:\n",
        "                        st.error(\"Invalid credentials!\")\n",
        "\n",
        "        with tab2:\n",
        "            with st.form(\"register_form\"):\n",
        "                new_email = st.text_input(\"Email\", key=\"reg_email\")\n",
        "                new_pass = st.text_input(\"Password\", type=\"password\", key=\"reg_pass\")\n",
        "                confirm_pass = st.text_input(\"Confirm Password\", type=\"password\", key=\"reg_confirm\")\n",
        "                role = st.selectbox(\"Role\", [\"General User\", \"Developer\", \"Student\"])\n",
        "                if st.form_submit_button(\"Register\"):\n",
        "                    if new_pass == confirm_pass:\n",
        "                        res = register_user(new_email, new_pass, role)\n",
        "                        if \"successfully\" in res:\n",
        "                            st.success(res)\n",
        "                        else:\n",
        "                            st.error(res)\n",
        "                    else:\n",
        "                        st.error(\"Passwords don't match!\")\n",
        "\n",
        "def show_main_app(payload):\n",
        "    with st.sidebar:\n",
        "        st.success(f\"👤 {payload['sub']}\")\n",
        "        st.info(f\"Role: {payload['role']}\")\n",
        "        if st.button(\"Logout\"):\n",
        "            st.session_state.token = None\n",
        "            st.rerun()\n",
        "\n",
        "    st.title(\"🤖 AI Code Assistant\")\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    if st.session_state.models is None:\n",
        "        with st.spinner(\"Loading AI models...\"):\n",
        "            st.session_state.models = setup_ai_models()\n",
        "        st.success(\"✅ Models loaded!\")\n",
        "\n",
        "    col1, col2 = st.columns([1,1])\n",
        "\n",
        "    with col1:\n",
        "        st.header(\"📝 Code Explanation\")\n",
        "        with st.form(\"explain_form\"):\n",
        "            code_input = st.text_area(\"Paste your code:\", height=200)\n",
        "            language = st.selectbox(\"Language\", [\"python\", \"javascript\", \"sql\", \"java\", \"cpp\"])\n",
        "            if st.form_submit_button(\"Explain\"):\n",
        "                if code_input.strip():\n",
        "                    with st.spinner(\"Analyzing code...\"):\n",
        "                        exp = explain_code(code_input, language, st.session_state.models)\n",
        "                        st.markdown(\"### 🎯 Explanation:\")\n",
        "                        st.markdown(exp)\n",
        "                else:\n",
        "                    st.warning(\"Please enter code!\")\n",
        "\n",
        "    with col2:\n",
        "        st.header(\"⚡ Code Generation\")\n",
        "        with st.form(\"generate_form\"):\n",
        "            prompt = st.text_area(\"Describe your task:\", height=200)\n",
        "            if st.form_submit_button(\"Generate\"):\n",
        "                if prompt.strip():\n",
        "                    with st.spinner(\"Generating code...\"):\n",
        "                        code = generate_code(prompt, st.session_state.models)\n",
        "                        st.markdown(\"### 🎯 Generated Code:\")\n",
        "                        st.code(code, language=\"python\")\n",
        "                else:\n",
        "                    st.warning(\"Please enter a description!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "'''\n",
        "\n",
        "# Save to file\n",
        "with open('integrated_app.py', 'w') as f:\n",
        "    f.write(complete_code)\n",
        "\n",
        "print(\"✅ integrated_app.py saved successfully!\")\n",
        "\n",
        "# ===============================\n",
        "# 🚀 RUN STREAMLIT IN COLAB VIA NGROK\n",
        "# ===============================\n",
        "\n",
        "!pip install pyngrok -q\n",
        "\n",
        "from pyngrok import ngrok\n",
        "\n",
        "NGROK_TOKEN = \"34TL2zzA6XsOcK1o13ldw2t42nV_3bTaPBRZ8ES9ekWCjGfDD\"  # replace with your token\n",
        "ngrok.set_auth_token(NGROK_TOKEN)\n",
        "ngrok.kill()\n",
        "\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"🌍 Public URL: {public_url}\")\n",
        "\n",
        "!streamlit run integrated_app.py --server.port 8501 --server.headless true &\n",
        "print(\"✅ App launched! Open the public URL above.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZZY5mu0VF-V",
        "outputId": "c19b73d7-c74d-4bd6-ff21-98fd094a3a1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ integrated_app.py saved successfully!\n",
            "🌍 Public URL: NgrokTunnel: \"https://nonbureaucratically-lumpish-lashaun.ngrok-free.dev\" -> \"http://localhost:8501\"\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.187.222.169:8501\u001b[0m\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-10-27T11:18:12+0000 lvl=warn msg=\"failed to check for update\" obj=updater err=\"Post \\\"https://update.equinox.io/check\\\": context deadline exceeded\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/integrated_app.py:55: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  'exp': datetime.utcnow() + timedelta(hours=2),\n",
            "/content/integrated_app.py:56: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  'iat': datetime.utcnow(),\n",
            "Loading CodeBERT...\n",
            "2025-10-27 11:18:32.393524: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761563912.414407   19355 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761563912.421213   19355 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761563912.438460   19355 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761563912.438489   19355 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761563912.438493   19355 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761563912.438496   19355 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-27 11:18:32.443719: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading Gemma...\n",
            "tokenizer_config.json: 100% 34.2k/34.2k [00:00<00:00, 94.0MB/s]\n",
            "tokenizer.model: 100% 4.24M/4.24M [00:00<00:00, 9.22MB/s]\n",
            "tokenizer.json: 100% 17.5M/17.5M [00:00<00:00, 85.1MB/s]\n",
            "special_tokens_map.json: 100% 636/636 [00:00<00:00, 4.22MB/s]\n",
            "config.json: 100% 627/627 [00:00<00:00, 4.77MB/s]\n",
            "model.safetensors.index.json: 100% 13.5k/13.5k [00:00<00:00, 55.5MB/s]\n",
            "Fetching 2 files:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/67.1M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 0.00/4.95G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   0% 40.9k/67.1M [00:00<15:17, 73.1kB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   1% 67.1M/4.95G [00:02<02:52, 28.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   2% 83.8M/4.95G [00:03<03:37, 22.3MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 67.1M/67.1M [00:05<00:00, 12.6MB/s]\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   2% 102M/4.95G [00:06<06:30, 12.4MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   3% 169M/4.95G [00:07<03:08, 25.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   4% 187M/4.95G [00:11<05:55, 13.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   7% 346M/4.95G [00:11<01:46, 43.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   8% 413M/4.95G [00:13<01:41, 44.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  10% 480M/4.95G [00:15<02:00, 37.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  10% 514M/4.95G [00:15<01:42, 43.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  12% 581M/4.95G [00:22<03:21, 21.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  13% 623M/4.95G [00:22<02:53, 25.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  14% 690M/4.95G [00:23<02:05, 34.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  15% 757M/4.95G [00:29<03:36, 19.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  17% 824M/4.95G [00:30<02:40, 25.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  18% 891M/4.95G [00:31<01:54, 35.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  19% 959M/4.95G [00:31<01:28, 45.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  20% 1.01G/4.95G [00:32<01:12, 54.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  22% 1.07G/4.95G [00:34<01:43, 37.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  23% 1.14G/4.95G [00:40<02:43, 23.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  24% 1.21G/4.95G [00:40<01:54, 32.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  26% 1.28G/4.95G [00:44<02:23, 25.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  27% 1.34G/4.95G [00:44<01:48, 33.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  29% 1.41G/4.95G [00:45<01:25, 41.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  30% 1.48G/4.95G [00:46<01:09, 50.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  31% 1.54G/4.95G [00:46<00:49, 69.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  33% 1.61G/4.95G [00:54<02:34, 21.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  34% 1.68G/4.95G [00:55<02:06, 25.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  35% 1.75G/4.95G [00:56<01:37, 32.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  37% 1.81G/4.95G [00:57<01:11, 43.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  38% 1.88G/4.95G [01:02<02:07, 24.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  39% 1.95G/4.95G [01:09<02:52, 17.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  41% 2.01G/4.95G [01:13<02:49, 17.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  42% 2.08G/4.95G [01:20<03:28, 13.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  43% 2.15G/4.95G [01:20<02:27, 19.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  45% 2.22G/4.95G [01:27<03:01, 15.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  46% 2.28G/4.95G [01:27<02:07, 20.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  46% 2.28G/4.95G [01:39<02:07, 20.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  48% 2.35G/4.95G [01:39<03:46, 11.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  49% 2.42G/4.95G [01:39<02:36, 16.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  50% 2.49G/4.95G [01:43<02:24, 17.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  51% 2.54G/4.95G [01:44<01:54, 20.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  53% 2.61G/4.95G [01:49<02:15, 17.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  54% 2.68G/4.95G [01:49<01:32, 24.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  55% 2.74G/4.95G [01:54<01:43, 21.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  57% 2.81G/4.95G [02:00<02:08, 16.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  58% 2.88G/4.95G [02:00<01:31, 22.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  60% 2.94G/4.95G [02:04<01:38, 20.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  61% 3.01G/4.95G [02:10<01:55, 16.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  62% 3.08G/4.95G [02:14<01:52, 16.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  64% 3.15G/4.95G [02:14<01:17, 23.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  64% 3.17G/4.95G [02:14<01:09, 25.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  65% 3.23G/4.95G [02:15<00:49, 34.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  67% 3.32G/4.95G [02:20<01:04, 25.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  69% 3.39G/4.95G [02:20<00:44, 34.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  70% 3.46G/4.95G [02:24<00:55, 26.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  72% 3.56G/4.95G [02:25<00:36, 37.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  73% 3.62G/4.95G [02:29<00:46, 28.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  75% 3.69G/4.95G [02:29<00:33, 38.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  76% 3.76G/4.95G [02:34<00:48, 24.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  77% 3.82G/4.95G [02:38<00:52, 21.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  79% 3.89G/4.95G [02:39<00:36, 28.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  80% 3.96G/4.95G [02:40<00:26, 36.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  81% 4.03G/4.95G [02:40<00:19, 47.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  82% 4.07G/4.95G [02:40<00:14, 58.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  84% 4.14G/4.95G [02:41<00:12, 62.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  85% 4.21G/4.95G [02:41<00:09, 80.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  86% 4.27G/4.95G [02:42<00:07, 91.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  88% 4.34G/4.95G [02:42<00:05, 104MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  89% 4.41G/4.95G [02:43<00:05, 98.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  91% 4.48G/4.95G [02:44<00:04, 105MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  92% 4.54G/4.95G [02:46<00:07, 53.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  93% 4.61G/4.95G [02:47<00:05, 61.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  95% 4.68G/4.95G [02:47<00:03, 77.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  96% 4.74G/4.95G [02:51<00:05, 40.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  97% 4.81G/4.95G [02:52<00:03, 40.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  99% 4.88G/4.95G [02:54<00:01, 38.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors: 100% 4.95G/4.95G [02:55<00:00, 28.2MB/s]\n",
            "Fetching 2 files: 100% 2/2 [02:55<00:00, 87.72s/it] \n",
            "Loading checkpoint shards: 100% 2/2 [00:24<00:00, 12.35s/it]\n",
            "generation_config.json: 100% 137/137 [00:00<00:00, 877kB/s]\n",
            "Loading DeepSeek...\n",
            "tokenizer_config.json: 1.87kB [00:00, 326kB/s]\n",
            "tokenizer.json: 1.37MB [00:00, 19.7MB/s]\n",
            "config.json: 100% 631/631 [00:00<00:00, 1.24MB/s]\n",
            "model.safetensors: 100% 2.69G/2.69G [01:49<00:00, 24.6MB/s]\n",
            "generation_config.json: 100% 119/119 [00:00<00:00, 856kB/s]\n",
            "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
          ]
        }
      ]
    }
  ]
}